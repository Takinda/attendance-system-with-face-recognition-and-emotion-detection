<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion Detection</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            text-align: center;
            background-color: #f5f5f5;
        }
        
        .container {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        
        .btn {
            background-color: #4CAF50;
            color: white;
            border: none;
            padding: 15px 30px;
            font-size: 16px;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        
        .btn:hover {
            background-color: #45a049;
        }
        
        .btn:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        
        .video-container {
            width: 100%;
            max-width: 640px;
            margin-top: 20px;
            display: none;
            position: relative;
        }
        
        video {
            width: 100%;
            border-radius: 8px;
            border: 2px solid #ddd;
        }
        
        canvas {
            display: none;
        }
        
        .controls {
            display: flex;
            justify-content: center;
            gap: 10px;
            margin-top: 10px;
        }
        
        .status-message {
            color: #555;
            margin-top: 10px;
        }
        
        /* Emotion log styles */
        .emotion-log {
            width: 100%;
            max-width: 640px;
            max-height: 200px;
            overflow-y: auto;
            border: 1px solid #ddd;
            border-radius: 8px;
            margin-top: 20px;
            padding: 10px;
            text-align: left;
            background-color: #f9f9f9;
            box-shadow: inset 0 0 5px rgba(0,0,0,0.1);
            display: none;
        }
        
        .log-entry {
            padding: 8px;
            border-bottom: 1px solid #eee;
            font-family: monospace;
        }
        
        .log-entry:last-child {
            border-bottom: none;
        }
        
        .log-entry.detecting {
            color: #777;
        }
        
        .log-entry.detected {
            font-weight: bold;
        }
        
        .emotion-angry { color: #e53935; }
        .emotion-disgust { color: #8bc34a; }
        .emotion-fear { color: #7b1fa2; }
        .emotion-happy { color: #ffc107; }
        .emotion-sad { color: #3f51b5; }
        .emotion-surprise { color: #ff9800; }
        .emotion-neutral { color: #607d8b; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Emotion Detection</h1>
        
        <p class="status-message" id="status-message">Click the button below to start emotion detection</p>
        
        <button id="start-btn" class="btn">Start Detection</button>
        
        <div class="video-container" id="video-container">
            <video id="video" autoplay playsinline></video>
            <canvas id="canvas"></canvas>
            
            <div class="controls">
                <button id="stop-btn" class="btn">Stop Detection</button>
            </div>
        </div>
        
        <!-- Emotion Log Box -->
        <div id="emotion-log" class="emotion-log">
            <div class="log-entry detecting">detection starting...</div>
        </div>
    </div>
    
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const startBtn = document.getElementById('start-btn');
            const stopBtn = document.getElementById('stop-btn');
            const videoEl = document.getElementById('video');
            const canvasEl = document.getElementById('canvas');
            const videoContainer = document.getElementById('video-container');
            const statusMessage = document.getElementById('status-message');
            const emotionLog = document.getElementById('emotion-log');
            
            let stream = null;
            let isRunning = false;
            let emotionUpdateInterval = null;
            let detectionCount = 0;
            const emotionClasses = ['Surprise', 'Disgust', 'Fear', 'Happy', 'Sad', 'Angry', 'Neutral'];
            
            // Add log entry
            function addLogEntry(message, isDetecting = true, emotion = null) {
                const entry = document.createElement('div');
                entry.classList.add('log-entry');
                
                if (isDetecting) {
                    entry.classList.add('detecting');
                    entry.innerText = message;
                } else {
                    entry.classList.add('detected');
                    
                    if (emotion) {
                        entry.classList.add('emotion-' + emotion.toLowerCase());
                        entry.innerText = message;
                    } else {
                        entry.innerText = message;
                    }
                }
                
                emotionLog.appendChild(entry);
                emotionLog.scrollTop = emotionLog.scrollHeight; // Auto-scroll to bottom
            }
            
            // Function to start camera and emotion detection
            async function startDetection() {
                try {
                    // Request camera access
                    stream = await navigator.mediaDevices.getUserMedia({ 
                        video: true,
                        audio: false
                    });
                    
                    // Display the video stream
                    videoEl.srcObject = stream;
                    videoContainer.style.display = 'block';
                    emotionLog.style.display = 'block';
                    startBtn.disabled = true;
                    statusMessage.textContent = 'Camera is active. Detecting emotions...';
                    statusMessage.style.color = 'green';
                    
                    // Clear previous log entries
                    emotionLog.innerHTML = '';
                    addLogEntry('detection starting...');
                    
                    // Set up canvas dimensions
                    canvasEl.width = videoEl.videoWidth;
                    canvasEl.height = videoEl.videoHeight;
                    
                    // Start the emotion detection
                    isRunning = true;
                    detectionCount = 0;
                    
                    // Start emotion detection interval (every 5 seconds)
                    emotionUpdateInterval = setInterval(detectEmotion, 5000);
                    
                    // Run the first detection
                    detectEmotion();
                    
                } catch (error) {
                    console.error('Error accessing camera:', error);
                    statusMessage.textContent = 'Error accessing camera: ' + error.message;
                    statusMessage.style.color = 'red';
                    addLogEntry('Error: ' + error.message, false);
                }
            }
            
            // Function to stop camera and detection
            function stopDetection() {
                if (stream) {
                    const tracks = stream.getTracks();
                    tracks.forEach(track => track.stop());
                    videoEl.srcObject = null;
                    stream = null;
                }
                
                if (emotionUpdateInterval) {
                    clearInterval(emotionUpdateInterval);
                    emotionUpdateInterval = null;
                }
                
                isRunning = false;
                videoContainer.style.display = 'none';
                startBtn.disabled = false;
                statusMessage.textContent = 'Emotion detection stopped';
                statusMessage.style.color = '#555';
                addLogEntry('detection stopped', false);
            }
            
            // Function to capture frame and send for emotion detection
            async function detectEmotion() {
                if (!isRunning || !videoEl.videoWidth) return;
                
                // Make sure canvas is properly sized
                if (canvasEl.width !== videoEl.videoWidth) {
                    canvasEl.width = videoEl.videoWidth;
                    canvasEl.height = videoEl.videoHeight;
                }
                
                detectionCount++;
                const currentDetection = detectionCount;
                addLogEntry(`detecting... (${currentDetection})`);
                
                const ctx = canvasEl.getContext('2d');
                ctx.drawImage(videoEl, 0, 0, canvasEl.width, canvasEl.height);
                
                // Convert to blob
                canvasEl.toBlob(async function(blob) {
                    try {
                        const formData = new FormData();
                        formData.append('image', blob, 'emotion.jpg');
                        
                        // Send to server
                        const response = await fetch('/detect-emotion', {
                            method: 'POST',
                            body: formData
                        });
                        
                        if (!response.ok) {
                            throw new Error('Error from server: ' + response.statusText);
                        }
                        
                        const result = await response.json();
                        
                        if (result.success && result.emotion !== undefined) {
                            // Get detected emotion
                            const detectedEmotion = emotionClasses[result.emotion];
                            
                            // Add to log
                            const timestamp = new Date().toLocaleTimeString();
                            addLogEntry(`emotion detected (${currentDetection}): ${detectedEmotion} [${timestamp}]`, false, detectedEmotion);
                            
                            console.log('Detected emotion:', detectedEmotion);
                        } else {
                            console.error('Invalid response from server:', result);
                            addLogEntry(`detection failed (${currentDetection}): invalid response`, false);
                        }
                    } catch (error) {
                        console.error('Error detecting emotion:', error);
                        statusMessage.textContent = 'Error: ' + error.message;
                        statusMessage.style.color = 'red';
                        addLogEntry(`detection error (${currentDetection}): ${error.message}`, false);
                    }
                }, 'image/jpeg', 0.9);
            }
            
            // Event listeners
            startBtn.addEventListener('click', startDetection);
            stopBtn.addEventListener('click', stopDetection);
            
            // Handle video loaded event to set canvas dimensions
            videoEl.addEventListener('loadedmetadata', function() {
                canvasEl.width = videoEl.videoWidth;
                canvasEl.height = videoEl.videoHeight;
            });
            
            // Clean up on page unload
            window.addEventListener('beforeunload', function() {
                if (emotionUpdateInterval) {
                    clearInterval(emotionUpdateInterval);
                }
                
                if (stream) {
                    const tracks = stream.getTracks();
                    tracks.forEach(track => track.stop());
                }
            });
        });
    </script>
</body>
</html>